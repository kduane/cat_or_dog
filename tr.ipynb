{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 - Problem Definition  \n",
    "\n",
    "#### 1.1 Broad Goals  \n",
    "\n",
    "I have multiple small animals underfoot while I'm coding, cats and dogs.  While my dog is canine shaped and behaved, she is a small breed and ruff-ly the same size or smaller than my cat.  \n",
    "\n",
    "#### 1.2 Data Source  \n",
    "\n",
    "This project combines two open source datasets to create a single sample:  \n",
    "    1. the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) which includes a limited number of samples for each category and over 120 separate dog breeds.  \n",
    "    2. the [Kaggle Cat Breeds Dataset](https://www.kaggle.com/ma7555/cat-breeds-dataset) which includes a limited number of samples for 67 different cat breeds\n",
    "\n",
    "#### 1.3 Problem Statement \n",
    "\n",
    "While identifying which pet is at my feet is an easy task for me as a human, it becomes a larger challenge for a computer. This project aims to build a binary image classification model to check whether a pet is a cat or a dog from a photo, with a stretch goal of applying real-time testing to a webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 - Data Gathering  \n",
    "####    2.1 Loading Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "target_breeds = ['coated_retriever','Maltese_dog','Afghan_hound'] \n",
    "\n",
    "for file in glob.glob('./data/Images/*/*.jpg'):\n",
    "    # retreive file name\n",
    "    file_name = os.path.basename(file)\n",
    "    # retreive breed name from directory name\n",
    "    breed = os.path.dirname(file).split('-')[-1]\n",
    "    # filter by targets\n",
    "    if breed in target_breeds:        \n",
    "        # load file\n",
    "        img_arr = cv2.imread(file)\n",
    "        #convert to color array\n",
    "        img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "        #reshape to uniform size 160x160x3\n",
    "        new_arr = cv2.resize(img_rgb, (160, 160))\n",
    "        #append to list as a 2-item dictionary\n",
    "        imgs.append({'species' : breed, 'image' : new_arr, 'orig_shape': img_arr.shape })\n",
    "\n",
    "#convert list to dataframe\n",
    "df = pd.DataFrame.from_dict(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3 - Exploratory Data Analysis  \n",
    "\n",
    "#### 3.1 Dataset Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4 - Modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train/Test/Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "# Starting Layer\n",
    "cnn.add(Conv2D(filters = 512,\n",
    "               kernel_size = (3, 3),\n",
    "               activation = 'relu',\n",
    "               input_shape = (160, 160, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)b))\n",
    "#second convolutional layer\n",
    "cnn.add(Conv2D(filters=256,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third convolutional layer\n",
    "cnn.add(Conv2D(filters=128,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#fourth convolutional layer\n",
    "cnn.add(Conv2D(filters=64,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten the metrics to fit into the Dense layers \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(512, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(256, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(128, activation = 'relu'))\n",
    "cnn.add(Dense(3, activation = 'softmax'))\n",
    "cnn.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "early_stop = EarlyStopping(patience = 5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cnn.fit(X_train, y_train,\n",
    "             batch_size = 64,\n",
    "             validation_data = (X_test, y_test),\n",
    "             epochs = 100,\n",
    "             callbacks = [early_stop],\n",
    "             verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit (conda)",
   "language": "python",
   "name": "python37764bitconda77dc9d652bc147c6a9d0ea8af6b5ba0e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
