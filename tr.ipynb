{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import jupyternotify\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scripts import common_quick_plots as qp\n",
    "\n",
    "np.random.seed(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5584dc7c-30e6-4e80-976d-b5b1e28c15ad\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5584dc7c-30e6-4e80-976d-b5b1e28c15ad\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Model Rendered\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Model Rendered\"\n",
    "\n",
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 - Problem Definition  \n",
    "\n",
    "#### 1.1 Broad Goals  \n",
    "\n",
    "I have multiple small animals underfoot while I'm coding, cats and dogs.  While my dog is canine shaped and behaved, she is a small breed and ruff-ly the same size or smaller than my cat.  \n",
    "\n",
    "#### 1.2 Data Source  \n",
    "\n",
    "This project combines two open source datasets to create a single sample:  \n",
    "    1. the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) which includes a limited number of samples for each category and over 120 separate dog breeds.  \n",
    "    2. the [Kaggle Cat Breeds Dataset](https://www.kaggle.com/ma7555/cat-breeds-dataset) which includes a limited number of samples for 67 different cat breeds\n",
    "\n",
    "#### 1.3 Problem Statement \n",
    "\n",
    "While identifying which pet is at my feet is an easy task for me as a human, it becomes a larger challenge for a computer. This project aims to build a binary image classification model to check whether a pet is a cat or a dog from a photo, with a stretch goal of applying real-time testing to a webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 - Data Gathering  \n",
    "####    2.1 Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "def load_resize(file, size = (160, 160)):\n",
    "    # load file\n",
    "    try:\n",
    "        img_arr = cv2.imread(file)\n",
    "        #convert to color array\n",
    "        img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "        #reshape to uniform size 160x160x3\n",
    "        return cv2.resize(img_rgb, size)\n",
    "    except:\n",
    "        print(f\"Invalid Path\")\n",
    "\n",
    "for path in glob.glob('./data/*'):\n",
    "    species = os.path.basename(path)\n",
    "    for breed in glob.glob(path +'/*'):\n",
    "        # pull a simplified name\n",
    "        if species == 'cat':\n",
    "            breed_name = breed.split('/')[-1]\n",
    "            for file in glob.glob(breed + '/*.jpg')[:350]: #limit to 350 per cat breed\n",
    "                file_name = os.path.basename(file)\n",
    "                # load file\n",
    "                image = load_resize(file)\n",
    "                imgs.append({'species' : species, \n",
    "                             'breed': breed_name, \n",
    "                             'image' : image\n",
    "                            })\n",
    "        else:\n",
    "            breed_name = breed.split('-')[-1]\n",
    "            for file in glob.glob(breed + '/*.jpg')[:150]: #limit to 150 per dog breed\n",
    "                file_name = os.path.basename(file)\n",
    "                # load file\n",
    "                image = load_resize(file)\n",
    "                imgs.append({'species' : species, \n",
    "                             'breed': breed_name, \n",
    "                             'image' : image\n",
    "                            })\n",
    "\n",
    "                \n",
    "#convert list to dataframe\n",
    "df = pd.DataFrame.from_dict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3 - Exploratory Data Analysis  \n",
    "\n",
    "#### 3.1 Dataset Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4 - Modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Path\n",
      "Invalid Path\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for path in glob.glob('./data/*'):\n",
    "    species = os.path.basename(path)\n",
    "    for breed in glob.glob(path +'/*'):\n",
    "        # pull a simplified name\n",
    "        if species == 'cat':\n",
    "            breed_name = breed.split('/')[-1]\n",
    "            for file in glob.glob(breed + '/*.jpg')[:350]: #limit to 350 per cat breed\n",
    "                file_name = os.path.basename(file)\n",
    "                # load file\n",
    "                try:\n",
    "                    img_arr = cv2.imread(file)\n",
    "                    #convert to color array\n",
    "                    img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                    #reshape to uniform size 160x160x3\n",
    "                    new_arr =  cv2.resize(img_rgb, (160, 160))\n",
    "                    X.append(new_arr)\n",
    "                    y.append(1)\n",
    "                except:\n",
    "                    print(f\"Invalid Path\")\n",
    "        else:\n",
    "            breed_name = breed.split('-')[-1]\n",
    "            for file in glob.glob(breed + '/*.jpg')[:150]: #limit to 150 per dog breed\n",
    "                file_name = os.path.basename(file)\n",
    "                # load file\n",
    "                try:\n",
    "                    img_arr = cv2.imread(file)\n",
    "                    #convert to color array\n",
    "                    img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                    #reshape to uniform size 160x160x3\n",
    "                    new_arr =  cv2.resize(img_rgb, (160, 160))\n",
    "                    X.append(new_arr)\n",
    "                    y.append(0)\n",
    "                except:\n",
    "                    print(f\"Invalid Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33102, 160, 160, 3), (33102,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = utils.to_categorical(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "# Starting Layer\n",
    "cnn.add(Conv2D(filters = 128,\n",
    "               kernel_size = (3, 3),\n",
    "               activation = 'relu',\n",
    "               input_shape = (160, 160, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#second convolutional layer\n",
    "cnn.add(Conv2D(filters=64,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third convolutional layer\n",
    "cnn.add(Conv2D(filters=128,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#fourth convolutional layer\n",
    "cnn.add(Conv2D(filters=32,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#fifth convolutional layer\n",
    "cnn.add(Conv2D(filters=32,            \n",
    "                     kernel_size=(3, 3),        \n",
    "                     activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#flatten the metrics to fit into the Dense layers \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(32, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(256, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(128, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(64, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(32, activation = 'relu'))\n",
    "cnn.add(Dense(2, activation = 'sigmoid'))\n",
    "cnn.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "early_stop = EarlyStopping(patience = 5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 158, 158, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 79, 79, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 77, 77, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        36896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 258,370\n",
      "Trainable params: 258,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "388/388 [==============================] - 738s 2s/step - loss: 0.6179 - accuracy: 0.6370 - val_loss: 0.3962 - val_accuracy: 0.8255\n",
      "Epoch 2/20\n",
      "388/388 [==============================] - 730s 2s/step - loss: 0.3138 - accuracy: 0.8728 - val_loss: 0.3437 - val_accuracy: 0.8742\n",
      "Epoch 3/20\n",
      "388/388 [==============================] - 719s 2s/step - loss: 0.2394 - accuracy: 0.9082 - val_loss: 0.2167 - val_accuracy: 0.9211\n",
      "Epoch 4/20\n",
      "388/388 [==============================] - 720s 2s/step - loss: 0.2169 - accuracy: 0.9184 - val_loss: 0.1906 - val_accuracy: 0.9300\n",
      "Epoch 5/20\n",
      "388/388 [==============================] - 695s 2s/step - loss: 0.2115 - accuracy: 0.9197 - val_loss: 0.2425 - val_accuracy: 0.9109\n",
      "Epoch 6/20\n",
      "388/388 [==============================] - 685s 2s/step - loss: 0.2060 - accuracy: 0.9237 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "Epoch 7/20\n",
      "388/388 [==============================] - 1749s 5s/step - loss: 0.1859 - accuracy: 0.9316 - val_loss: 0.2207 - val_accuracy: 0.9247\n",
      "Epoch 8/20\n",
      "388/388 [==============================] - 731s 2s/step - loss: 0.1897 - accuracy: 0.9280 - val_loss: 0.1748 - val_accuracy: 0.9413\n",
      "Epoch 9/20\n",
      "388/388 [==============================] - 715s 2s/step - loss: 0.1840 - accuracy: 0.9318 - val_loss: 0.2159 - val_accuracy: 0.9222\n",
      "Epoch 10/20\n",
      "388/388 [==============================] - 714s 2s/step - loss: 0.1861 - accuracy: 0.9314 - val_loss: 0.1710 - val_accuracy: 0.9392\n",
      "Epoch 11/20\n",
      "388/388 [==============================] - 710s 2s/step - loss: 0.1804 - accuracy: 0.9333 - val_loss: 0.1842 - val_accuracy: 0.9381\n",
      "Epoch 12/20\n",
      "388/388 [==============================] - 715s 2s/step - loss: 0.1714 - accuracy: 0.9371 - val_loss: 0.2028 - val_accuracy: 0.9271\n",
      "Epoch 13/20\n",
      "388/388 [==============================] - 1229s 3s/step - loss: 0.1642 - accuracy: 0.9406 - val_loss: 0.1857 - val_accuracy: 0.9380\n",
      "Epoch 14/20\n",
      "388/388 [==============================] - 691s 2s/step - loss: 0.1643 - accuracy: 0.9416 - val_loss: 0.2414 - val_accuracy: 0.9166\n",
      "Epoch 15/20\n",
      "388/388 [==============================] - 672s 2s/step - loss: 0.1676 - accuracy: 0.9392 - val_loss: 0.1924 - val_accuracy: 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%notify` not found.\n"
     ]
    }
   ],
   "source": [
    "%%notify -o\n",
    "res = cnn.fit(X_train, y_train,\n",
    "             batch_size = 64,\n",
    "             validation_data = (X_test, y_test),\n",
    "             epochs = 20,\n",
    "             callbacks = [early_stop],\n",
    "             verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.plot_loss(res, 'Loss by Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.plot_accuracy(res, 'Accuracy by Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.plot_confusion_matrix(cnn, X_test, y_test, \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit (conda)",
   "language": "python",
   "name": "python37764bitconda77dc9d652bc147c6a9d0ea8af6b5ba0e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
